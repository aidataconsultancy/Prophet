[app]
app_intro = """
Looking to make predictions based on historical data? 
Dive into the world of time series forecasting effortlessly using this model.
How Does It Work?
* __Upload Your Data__: Start by uploading your time series dataset.
* __Data Prep Made Simple__: Tweak your dataset! Filter, aggregate, resample, or clean it up.
Not sure how? Guidance is just a click away in our sidebar.
* __Tuning Your Model__: Use our default settings or get hands-on and adjust the parameters.
Tooltips offer insights on each parameter. Hover over to understand its influence on predictions.
* __Evaluating Your Model__: Choose your evaluation method, define the metrics, and pick the level of detail to scrutinise your model's efficiency. 
* __Predict The Future__:Once you’re set, make forecasts for dates outside of your dataset.
Witness the predictive power of your trained model.
* __Download Your Results__:Once you’re set, make forecasts for dates outside of your dataset.
Witness the predictive power of your trained model. \n


Satisfied with your experiments? Hit "save experiment" and download all your plots and data to your device.
.
"""

[tooltips]
launch_forecast = """
Bear in mind, every time you tweak a parameter in the sidebar, we'll whip up a fresh forecast for you.
"""
track_experiments = """
Check to get a link to download a report at the bottom of the page.
The report contains the data, the plots and the config used to get them.
Use it only when you actually want to save experiments, as it might make processings a bit slower.
"""
upload_choice = """
* Tick the box to load a sample dataset and discover the capabilities of this app. 
* To use your own data, simply untick the box.
"""
custom_config = """
Follow these steps to provide your own configuration file:
* Download config template and instructions files above.
* Edit config template file with your own specifications.
* Upload the edited file below.
"""
custom_config_choice = """
* Check if you want to upload a configuration file with specifications adapted to your usage.
* Uncheck to enter directly your specifications in the sidebar.
"""
dataset_upload = """
Your csv file should have at least a column with dates and a column with numeric values to forecast.
"""
toy_dataset = """
Pick a Sample Dataset:
* __Retail sales__: Daily sales from Walmart stores.
* __House sales__: Monthly house sales in London boroughs.
* __Energy consumption__:Daily energy consumption of households.
* __Weather__: Hourly temperature readings in Madrid.
* __Commodity prices__: Weekly corn prices in USD per bushel.
"""
date_format = """
For example "%Y-%m-%d" or "%d/%m/%Y %H:%M:%S".
"""
separator = """
Delimiter used in the csv file
"""
date_column = """
The column recognised as a date.
"""
target_column = """
The quantity you wish to forecast.
"""
dimensions = """
Keep in mind, the model is tailored to forecast a single series at once.
If your dataset hosts multiple time series, you might wish to sift through or combine these series.
The dimensions refer to the columns allowing such filtering and aggregation. \n
Choosing dimensions isn't mandatory. 
If you opt not to pick any, every target value falling on the same date will be merged, 
resulting in a single target value for each date. \n
For instance: Imagine a dataset detailing sales from three countries: A, B, and C. 
You could pinpoint countries B and C, aiming to predict the combined sales from both.
"""
dimensions_keep = """
Check to keep all values or uncheck to filter values on column
"""
dimensions_filter = """
All values selected will be aggregated into one time series.
"""
dimensions_agg = """
Function used to aggregate the different time series into one.
"""
resample_choice = """
Check to resample your dataset at a lower time frequency.
"""
resample_new_freq = """
Both training and forecasting will be done at this new frequency.
"""
resample_agg = """
Original values have to be aggregated because the new frequency is lower than the original one.  \n
Example: For a dataset originally at daily frequency and resampled at weekly frequency,
the 7 values of each week could be averaged, summed, or we could keep the min or max value of the week.
"""
remove_days = """
Days selected will be removed from both training and forecasting periods.
"""
del_zeros = """
Check if the quantity to forecast should never be 0.
"""
del_negative = """
Check if the quantity to forecast should never be striclty negative.
"""
log_transform = """
Applying a log transformation to the target before modelling might increase performance.
"""
choice_eval = """
* Tick this box if you wish to assess your model using either a training/validation split or a cross-validation method.
* Untick if you'd rather bypass the evaluation and proceed directly to forecasting.
"""
choice_cv = """
* Tick to embrace the thoroughness of cross-validation for performance assessment.
* Untick if you prefer the straightforward approach of a simple training/validation split.
"""
cv_n_folds = """
Number of distinct training/validation pairs to include in the cross-validation.
"""
cv_horizon = """
Length of validation period for each fold.
"""
choice_forecast = """
* Tick this box if you wish to project a forecast for days that aren't captured in your dataset. 
By doing so, the model harnesses the entirety of your dataset for training, 
and the forecast will appear at the dashboard's lower section.
In that case, the model will be trained on the whole dataset and the forecast will be visible at the bottom of the dashboard.
* Untick if your focus is solely on gauging the model's performance using existing data.
"""
forecast_horizon = """
Length of the period to forecast after the last date available in input dataset.
"""
holidays_prior_scale = """
This setting controls the extent to which holidays impact your forecasts. 
Adjusting it allows you to fine-tune the prominence of holiday-related effects in your predictions.
"""
changepoint_prior_scale = """
The model is adept at spotting 'changepoints' in the trend on its own.
This particular setting fine-tunes the trend's adaptability 
by regulating the number of changepoints identified. 
By ramping up this value, you endow the trend with increased flexibility, 
leading to the recognition of more changepoints.
 However, tread cautiously. A hyper-flexible trend can lead to overfitting, 
 inadvertently folding seasonal patterns into the trend – an outcome best avoided.
"""
seasonality = """
Decide if you'd like to factor in this particular seasonality when modelling. 
In the 'auto' setting, The model will only incorporate seasonality if there's sufficient historical data – that's 
at least two full cycles of the seasonality in question 
(for instance, two years of data for an annual seasonality).
"""
seasonality_prior_scale = """
This setting governs the intensity of seasonal influences on your forecasts.
If you notice that the seasonality seems excessively pronounced or distorted in the predictions, 
consider reducing this value for a more balanced outcome. 
"""
seasonality_mode = """
Determines how seasonality components should be integrated with the predictions:
* Use `additive` when seasonality trend should be “constant” over the entire period (typically for linear trends).
* Use `multiplicative` to increase the importance of the seasonality over time (typically for exponential trends).
"""
seasonality_fourier = """
Each seasonality is a fourier series as a function of time. The fourier order is the number of terms in the series.
A higher order can fit more complex and quickly changing seasonality patterns,
but it will also make overfitting more likely.
You can use the seasonality components plots of this app to tune this parameter visually.
"""
seasonality_name = """
Choose a name for your custom seasonality. That name will appear on components plots, on the right.
"""
seasonality_period = """
Number of days of each cycle.
"""
add_custom_seasonality = """
Check to include a specific seasonality in the model (other than the ones listed above).
"""
holidays_country = """
To add country-specific holidays, start by selecting a single country (multiple countries not supported). \
Prophet will try to model the impact of each selected holidays on the target variable.
"""
public_holidays = """
Public holidays such as Bastille day in France, Christmas, 4th of July in the US, etc
"""
school_holidays = """
School holidays. Not available for all countries at this time.
"""
lockdown_events = """
Nation-wide lockdown events due to covid 19 pandemic in 2020-2021. Not available for all countries at this time.
"""
add_all_regressors = """
Regressors are quantities related to the target, that will help Prophet adjusting its forecasts.
Check to include all regressors detected in your dataset, or select them yourself.
"""
select_regressors = """
You don't necessarily have to select regressors. Only select those that improve model performance.
"""
regressor_prior_scale = """
Determines the magnitude of the regressor effect on your predictions.
"""
growth = """
This parameter determines how the trend will evolve between change points:
* `linear`: The trend will be a line with a slope that can vary at each changepoint.
* `flat`: The trend will be constant over time.
* `logistic`: The trend will look like a logistic curve between each changepoint.
Useful if the time series has a cap or a floor that can't be exceeded.
"""
cap = """
Upper value that can't be exceeded by the trend.
"""
floor = """
Lower value that can't be exceeded by the trend.
"""
changepoint_range = """
Proportion of training data that will be used to detect changepoints in the trend.
By default, changepoints are only inferred for the first 80% data points in order to avoid overfitting fluctuations
at the end of the time series. But you can increase this range if the final fluctuations are significant.
"""
metrics = """
Metrics that will be used to compare model predictions to the ground truth.
"""
eval_set = """
Choose whether to evaluate the model on training data or validation data.
You should look at validation data to assess model performance,
but evaluation on training data can also be useful to detect overfitting.
"""
eval_granularity = """
Granularity at which predictions on evaluation set will be averaged.
Select 'Global' if you want to compute performance on the whole evaluation set.
"""
choice_agg_perf = """
Check to sum all predictions and true values at the selected granularity before computing performance metrics.
Be careful, this method can be misleading as under-prediction errors could be compensated by over-prediction errors.
"""

[plots]
overview = """
This visualization displays several information:
* The blue line shows the __predictions__ made by the model on both training and validation periods.
* The blue shade around is a __80% uncertainty interval__ on these predictions,
obtained through a Monte Carlo simulation.
* The black points are the __actual values__ of the target on training period.
* The red line is the __trend__ estimated by the model,
and the vertical lines show the __changepoints__ at which this trend evolves.

You can use the slider at the bottom or the buttons at the top to focus on a specific time period.
"""
metrics = """
The following metrics can be computed to evaluate model performance:
* __Mean Absolute Percentage Error (MAPE)__: Measures the average absolute size of each error in percentage
of the truth. This metric is not ideal for low-volume forecasts,
because being off by a few units can increase the percentage error signficantly.
It can't be calculated if the true value is 0 (here samples are excluded from calculation if true value is 0).
* __Symmetric Mean Absolute Percentage Error (SMAPE)__: Slight variation of the MAPE,
it measures the average absolute size of each error in percentage of the truth summed with the forecast.
It is therefore a bit more robust to 0 values.
* __Mean Squared Error (MSE)__: Measures the average squared difference between forecasts and true values.
This metric is not ideal with noisy data,
because a very bad forecast can increase the global error signficantly as all errors are squared.
* __Root Mean Squared Error (RMSE)__: Square root of the MSE.
This metric is more robust to outliers than the MSE,
as the square root limits the impact of large errors in the global error.
* __Mean Absolute Error (MAE)__: Measures the average absolute error.
This metric can be interpreted as the absolute average distance between the best possible fit and the forecast.
"""
components = """
The forecast generated by Prophet is the sum of different contributions:
* Trend
* Seasonalities
* Other factors such as holidays or external regressors

The following visualization shows this breakdown and allows you to understand how each component contributes
to the final value forecasted by the model.
"""
waterfall = """
This plot shows the contributions of each components on a specific period of time.
All contributions are averaged over the selected period.
"""
future = """
This visualization can be read in the same way as the overview plot:
* The blue line shows the predictions made by the model for the period to be forecasted.
* The blue shade is a 80% uncertainty interval.
* The red line is the trend estimated by the model.
"""
helper_metrics = """
The following table and plots allow you to evaluate model performance. Go to the **Evaluation** section of the sidebar if you wish to customize evaluation settings by:
* Adding more metrics
* Changing evaluation period
* Computing performance at a different granularity to understand on which periods performance drops
"""
helper_errors = """
The following plots can help you to detect patterns in forecasting errors:
* The first one shows forecasts vs the ground truth on evaluation period.
* The second one helps to find the worst performing forecasts (ie points far from the red line).
* The third one shows how errors are distributed (see whether the model makes under-prediction or over-prediction errors).

If you detect a recurring error, change cleaning options or model parameters to try to correct it.
"""

[links]
repo = "https://github.com/aidataconsultancy/Prophet"
article = "https://medium.com/artefact-engineering-and-data-science/visual-time-series-forecasting-with-streamlit-prophet-71d86a769928"
